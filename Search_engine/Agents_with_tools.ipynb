{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e602ef87",
   "metadata": {},
   "source": [
    "#### Search Engine with Agents and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a10911",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tools creation -> Arxiv\n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efdd7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inbuilt tool of Wikipedia\n",
    "\n",
    "wikipedia_api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=300)\n",
    "wiki = WikipediaQueryRun(api_wrapper=wikipedia_api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02bc8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_api_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=300)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae036618",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki, arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "815590bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7fd0ecfbf820>, search_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build own custom tools\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector_store = FAISS.from_documents(documents, HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
    "retriever = vector_store.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b9d2c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith-search'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever, \"langsmith-search\", \"Search any information about Langsmith\")\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8311491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/opt/conda/envs/myenv/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=300)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=300)),\n",
       " StructuredTool(name='langsmith-search', description='Search any information about Langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=<function create_retriever_tool.<locals>.func at 0x7fd0ed109b40>, coroutine=<function create_retriever_tool.<locals>.afunc at 0x7fd0ed109a20>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [wiki, arxiv, retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000ceec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x7fd0ecedd060>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7fd0ecedcf70>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run this tools with Agents and LLMs\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = \"Your_API_KEY\"\n",
    "\n",
    "model = ChatGroq(model=\"qwen/qwen3-32b\", groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_classic import hub\n",
    "from langchain_classic.agents import initialize_agent, AgentType\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "519c3e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': \"wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\narxiv - A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\\nlangsmith-search(query: 'str', callbacks: 'Callbacks' = None) -> 'str | tuple[str, list[Document]]' - Search any information about Langsmith\", 'tool_names': 'wikipedia, arxiv, langsmith-search'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x7fd0ecedd060>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7fd0ecedcf70>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| ReActSingleInputOutputParser()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use Agents\n",
    "from langchain_classic.agents import create_react_agent\n",
    "\n",
    "agent = create_react_agent(llm=model, prompt=prompt, tools=tools)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42090a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': \"wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\narxiv - A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\\nlangsmith-search(query: 'str', callbacks: 'Callbacks' = None) -> 'str | tuple[str, list[Document]]' - Search any information about Langsmith\", 'tool_names': 'wikipedia, arxiv, langsmith-search'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x7fd0ecedd060>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7fd0ecedcf70>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/opt/conda/envs/myenv/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=300)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=300)), StructuredTool(name='langsmith-search', description='Search any information about Langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=<function create_retriever_tool.<locals>.func at 0x7fd0ed109b40>, coroutine=<function create_retriever_tool.<locals>.afunc at 0x7fd0ed109a20>)])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent executor\n",
    "\n",
    "from langchain_classic.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e60cb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, let's see. The user is asking about the paper with ID 1706.03762. I need to figure out what this paper is about. First, I remember that arXiv assigns IDs in the format year.month, so 1706 would be June 2017. The full ID is probably 1706.03762.\n",
      "\n",
      "Since the user wants information about this specific paper, the best tool to use here is arxiv. The arxiv wrapper can search for papers by their ID. So I should use the arxiv tool with the query '1706.03762' to get details.\n",
      "\n",
      "Let me execute that. Using arxiv with the input '1706.03762' should retrieve the title, authors, and abstract. Once I have that information, I can summarize it for the user.\n",
      "\n",
      "Wait, I should check if the arxiv tool can handle the full ID. Sometimes, people might input just the first part, but the tool might need the full arXiv ID. However, in this case, the user provided the full ID, so it should work. Let me proceed.\n",
      "</think>\n",
      "\n",
      "Action: arxiv\n",
      "Action Input: 1706.03762\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks \u001b[0m\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, let me process what I found. The user asked about paper 1706.03762. Using the arxiv tool, I looked it up and got the title \"Attention Is All You Need\" published in 2023. The authors are listed, and the summary mentions it's about sequence transduction models using recurrent or convolutional neural networks. Wait, but I recall that the famous \"Attention Is All You Need\" paper was actually published in 2017, not 2023. The arXiv ID 1706.03762 should correspond to that 2017 paper. Maybe there's a mistake in the observation here. Let me double-check. The user provided the ID 1706.03762, which breaks down to 2017-06 (June 2017) and the number 03762. The correct paper with this ID is indeed the original Transformer paper by Vaswani et al. published in 2017. The observation might have an error in the publication date. So, the correct details are: the paper introduces the Transformer model, which uses self-attention mechanisms and replaces traditional RNNs or CNNs. The summary provided in the observation seems incomplete. To ensure accuracy, maybe I should confirm the correct information. The paper's main contribution is the Transformer architecture, which has become foundational in NLP. The arxiv tool's response might have a typo in the date, but the title and authors are correct. Therefore, the answer should highlight the Transformer model, self-attention, and its impact on sequence transduction tasks like machine translation.\n",
      "</think>\n",
      "\n",
      "Thought: The paper titled \"Attention Is All You Need\" (arXiv ID: 1706.03762) is a groundbreaking work in natural language processing. It introduces the **Transformer** architecture, which relies entirely on self-attention mechanisms to process sequential data, eliminating the need for recurrent or convolutional layers. This model revolutionized tasks like machine translation and became the foundation for subsequent architectures such as BERT and GPT.\n",
      "\n",
      "Final Answer: The paper \"Attention Is All You Need\" (arXiv:1706.03762) presents the Transformer, a neural network architecture that uses self-attention to handle sequence transduction tasks. It replaced traditional recurrent/convolutional models, enabling parallel processing and achieving state-of-the-art results in NLP tasks like machine translation. The work by Vaswani et al. (2017) laid the foundation for modern language models.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the paper 1706.03762 about?',\n",
       " 'output': 'The paper \"Attention Is All You Need\" (arXiv:1706.03762) presents the Transformer, a neural network architecture that uses self-attention to handle sequence transduction tasks. It replaced traditional recurrent/convolutional models, enabling parallel processing and achieving state-of-the-art results in NLP tasks like machine translation. The work by Vaswani et al. (2017) laid the foundation for modern language models.'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"what is the paper 1706.03762 about?\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
