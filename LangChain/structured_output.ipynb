{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9153d274",
   "metadata": {},
   "source": [
    "#### Pydantic\n",
    "\n",
    "Pydantic models provide the richest feature set with field validation, descriptions and nested structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5919b256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x7f034e23d6c0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f034e23d5d0>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "model = init_chat_model(\"groq:qwen/qwen3-32b\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6e6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    title:str=Field(description=\"Title of the movie\")\n",
    "    year:int=Field(description=\"Movie was released in this year\")\n",
    "    director:str=Field(description=\"The director of the movie\")\n",
    "    rating:float=Field(description=\"Movie rating out of 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184cc729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x7f034e23d6c0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f034e23d5d0>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Movie', 'description': '', 'parameters': {'properties': {'title': {'description': 'Title of the movie', 'type': 'string'}, 'year': {'description': 'Movie was released in this year', 'type': 'integer'}, 'director': {'description': 'The director of the movie', 'type': 'string'}, 'rating': {'description': 'Movie rating out of 5', 'type': 'number'}}, 'required': ['title', 'year', 'director', 'rating'], 'type': 'object'}}}], 'ls_structured_output_format': {'kwargs': {'method': 'function_calling'}, 'schema': {'type': 'function', 'function': {'name': 'Movie', 'description': '', 'parameters': {'properties': {'title': {'description': 'Title of the movie', 'type': 'string'}, 'year': {'description': 'Movie was released in this year', 'type': 'integer'}, 'director': {'description': 'The director of the movie', 'type': 'string'}, 'rating': {'description': 'Movie rating out of 5', 'type': 'number'}}, 'required': ['title', 'year', 'director', 'rating'], 'type': 'object'}}}}, 'tool_choice': {'type': 'function', 'function': {'name': 'Movie'}}}, config={}, config_factories=[])\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Movie'>])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_structure = model.with_structured_output(Movie)\n",
    "model_with_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca6d2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie(title='Annabelle', year=2014, director='John R. Leonetti', rating=5.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model_with_structure.invoke(\"Provide details about the movie Annabelle\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b086574",
   "metadata": {},
   "source": [
    "#### Message output alongside parsed structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "591b59f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': AIMessage(content='', additional_kwargs={'reasoning_content': \"Okay, the user is asking for details about the movie Annabelle. Let me check the tools available. There's a Movie function that requires title, year, director, and rating. I need to fill these parameters. First, I know Annabelle is a horror movie. Let me recall, the director is John Weaver. The release year was 2014. The rating... maybe around 3.5 out of 5. Let me confirm these details. Wait, is the director correct? I think John Weaver did direct it. Yeah, that's right. So I'll structure the tool call with those parameters.\\n\", 'tool_calls': [{'id': 'q1b81en19', 'function': {'arguments': '{\"director\":\"John Weaver\",\"rating\":3.5,\"title\":\"Annabelle\",\"year\":2014}', 'name': 'Movie'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 175, 'prompt_tokens': 222, 'total_tokens': 397, 'completion_time': 0.362114011, 'completion_tokens_details': {'reasoning_tokens': 127}, 'prompt_time': 0.008782221, 'prompt_tokens_details': None, 'queue_time': 0.159328769, 'total_time': 0.370896232}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019be068-fdb0-7c10-9a67-853ad5028ce4-0', tool_calls=[{'name': 'Movie', 'args': {'director': 'John Weaver', 'rating': 3.5, 'title': 'Annabelle', 'year': 2014}, 'id': 'q1b81en19', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 222, 'output_tokens': 175, 'total_tokens': 397, 'output_token_details': {'reasoning': 127}}),\n",
       " 'parsed': Movie(title='Annabelle', year=2014, director='John Weaver', rating=3.5),\n",
       " 'parsing_error': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Movie(BaseModel):\n",
    "    title:str=Field(..., description=\"Title of the movie\")\n",
    "    year:int=Field(..., description=\"Movie was released in this year\")\n",
    "    director:str=Field(..., description=\"The director of the movie\")\n",
    "    rating:float=Field(..., description=\"Movie rating out of 5\")\n",
    "\n",
    "model_with_structure = model.with_structured_output(Movie, include_raw=True)\n",
    "response = model_with_structure.invoke(\"Provide details about the movie Annabelle\", )\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7840bde",
   "metadata": {},
   "source": [
    "#### Nested structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3152dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MovieDetails(title='Avengers', year=2012, cast=[Actor(name='Robert Downey Jr.', role='Iron Man'), Actor(name='Chris Evans', role='Captain America'), Actor(name='Mark Ruffalo', role='Hulk'), Actor(name='Chris Hemsworth', role='Thor'), Actor(name='Scarlett Johansson', role='Black Widow'), Actor(name='Jeremy Renner', role='Hawkeye')], genres=['Action', 'Sci-Fi', 'Adventure'], budget=240.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Actor(BaseModel):\n",
    "    name: str\n",
    "    role: str\n",
    "\n",
    "class MovieDetails(BaseModel):\n",
    "    title: str\n",
    "    year: int\n",
    "    cast: list[Actor]\n",
    "    genres: list[str]\n",
    "    budget: float | None = Field(None, description=\"Budget in millions USD\")\n",
    "\n",
    "model_with_structure = model.with_structured_output(MovieDetails)\n",
    "\n",
    "response = model_with_structure.invoke(\"Provide details about the movie Avengers\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a42945",
   "metadata": {},
   "source": [
    "#### TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9034e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'director': 'Joss Whedon', 'rating': 8, 'title': 'The Avengers', 'year': 2012}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import TypedDict,Annotated\n",
    "\n",
    "class MovieDict(TypedDict):\n",
    "    \"\"\"A movie with details.\"\"\"\n",
    "    title: Annotated[str, ..., \"The title of the movie\"]\n",
    "    year: Annotated[int, ..., \"The year the movie was released\"]\n",
    "    director: Annotated[str, ..., \"The director of the movie\"]\n",
    "    rating: Annotated[float, ..., \"The movie's rating out of 10\"]\n",
    "\n",
    "\n",
    "model_withtypedict=model.with_structured_output(MovieDict)\n",
    "response=model_withtypedict.invoke(\"Please provide the details of the movie avengers\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37096253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'budget': 220800000,\n",
       " 'cast': [{'name': 'Robert Downey Jr.', 'role': 'Tony Stark / Iron Man'},\n",
       "  {'name': 'Chris Evans', 'role': 'Steve Rogers / Captain America'},\n",
       "  {'name': 'Mark Ruffalo', 'role': 'Bruce Banner / Hulk'},\n",
       "  {'name': 'Chris Hemsworth', 'role': 'Thor'},\n",
       "  {'name': 'Scarlett Johansson', 'role': 'Natasha Romanoff / Black Widow'},\n",
       "  {'name': 'Jeremy Renner', 'role': 'Clint Barton / Hawkeye'}],\n",
       " 'genres': ['Action', 'Science Fiction', 'Superhero'],\n",
       " 'title': 'Avengers',\n",
       " 'year': 2012}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "class Actor(TypedDict):\n",
    "    name: str\n",
    "    role: str\n",
    "\n",
    "class MovieDetails(TypedDict):\n",
    "    title: str\n",
    "    year: int\n",
    "    cast: list[Actor]\n",
    "    genres: list[str]\n",
    "    budget: float | None = Field(None, description=\"Budget in millions USD\")\n",
    "\n",
    "model_with_structure = model.with_structured_output(MovieDetails)\n",
    "\n",
    "response = model_with_structure.invoke(\"Provide details about the movie Avengers\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5f2a1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_input_tokens': 131072,\n",
       " 'max_output_tokens': 16384,\n",
       " 'image_inputs': False,\n",
       " 'audio_inputs': False,\n",
       " 'video_inputs': False,\n",
       " 'image_outputs': False,\n",
       " 'audio_outputs': False,\n",
       " 'video_outputs': False,\n",
       " 'reasoning_output': True,\n",
       " 'tool_calling': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163ba035",
   "metadata": {},
   "source": [
    "#### Data Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ca5ff99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Extract contact info from: John Doe, john@example.com, (555) 123-4567', additional_kwargs={}, response_metadata={}, id='0a8bf976-efac-4768-9377-02d73ee1c961'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, let\\'s see. The user wants me to extract contact information from the given text: \"John Doe, john@example.com, (555) 123-4567\". The tools provided include a ContactInfo function with parameters for name, email, and phone. All three are required.\\n\\nFirst, I need to parse the input. The name is \"John Doe\", which is straightforward. The email is \"john@example.com\". The phone number is \"(555) 123-4567\". I should check if the phone number is in the correct format. The function\\'s parameters expect a string for each, so I don\\'t need to change the format. Just make sure all three are included. Since all required fields are present, I can call the ContactInfo function with these details.\\n', 'tool_calls': [{'id': 'r9h6k4325', 'function': {'arguments': '{\"email\":\"john@example.com\",\"name\":\"John Doe\",\"phone\":\"(555) 123-4567\"}', 'name': 'ContactInfo'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 222, 'prompt_tokens': 227, 'total_tokens': 449, 'completion_time': 0.405610973, 'completion_tokens_details': {'reasoning_tokens': 171}, 'prompt_time': 0.008901659, 'prompt_tokens_details': None, 'queue_time': 0.16048742, 'total_time': 0.414512632}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019be09f-8df0-7db1-86eb-f107c89acba6-0', tool_calls=[{'name': 'ContactInfo', 'args': {'email': 'john@example.com', 'name': 'John Doe', 'phone': '(555) 123-4567'}, 'id': 'r9h6k4325', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 227, 'output_tokens': 222, 'total_tokens': 449, 'output_token_details': {'reasoning': 171}}),\n",
       "  ToolMessage(content=\"Returning structured response: name='John Doe' email='john@example.com' phone='(555) 123-4567'\", name='ContactInfo', id='c9f807d1-1aa8-486a-bcef-31099ce30dbc', tool_call_id='r9h6k4325')],\n",
       " 'structured_response': ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Contact information for a person.\"\"\"\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    email: str = Field(description=\"The email address of the person\")\n",
    "    phone: str = Field(description=\"The phone number of the person\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"groq:qwen/qwen3-32b\",\n",
    "    response_format=ContactInfo  # Auto-selects ProviderStrategy\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36e59aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['structured_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f042faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Doe', 'email': 'john@example.com', 'phone': '(555) 123-4567'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TypedDict\n",
    "class ContactInfo(TypedDict):\n",
    "    \"\"\"Contact information for a person.\"\"\"\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    email: str = Field(description=\"The email address of the person\")\n",
    "    phone: str = Field(description=\"The phone number of the person\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"groq:qwen/qwen3-32b\",\n",
    "    response_format=ContactInfo  # Auto-selects ProviderStrategy\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result['structured_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "6e9352eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Initializing ChatOpenAI requires the langchain-openai package. Please install it with `pip install langchain-openai`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/langchain/chat_models/base.py:102\u001b[0m, in \u001b[0;36m_import_module\u001b[0;34m(module, class_name)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Extract package name from module path (e.g., \"langchain_azure_ai.chat_models\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# becomes \"langchain-azure-ai\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     email: \u001b[38;5;28mstr\u001b[39m \n\u001b[1;32m     10\u001b[0m     phone: \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m---> 12\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mContactInfo\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Auto-selects ProviderStrategy\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m result \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract contact info from: John Doe, john@example.com, (555) 123-4567\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m     19\u001b[0m })\n\u001b[1;32m     21\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructured_response\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/langchain/agents/factory.py:691\u001b[0m, in \u001b[0;36mcreate_agent\u001b[0;34m(model, tools, system_prompt, middleware, response_format, state_schema, context_schema, checkpointer, store, interrupt_before, interrupt_after, debug, name, cache)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# init chat model\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 691\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;66;03m# Convert system_prompt to SystemMessage if needed\u001b[39;00m\n\u001b[1;32m    694\u001b[0m system_message: SystemMessage \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/langchain/chat_models/base.py:451\u001b[0m, in \u001b[0;36minit_chat_model\u001b[0;34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m has been set but no fields are configurable. Set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    447\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    448\u001b[0m     )\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[1;32m    457\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/langchain/chat_models/base.py:474\u001b[0m, in \u001b[0;36m_init_chat_model_helper\u001b[0;34m(model, model_provider, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_init_chat_model_helper\u001b[39m(\n\u001b[1;32m    468\u001b[0m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    470\u001b[0m     model_provider: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    472\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseChatModel:\n\u001b[1;32m    473\u001b[0m     model, model_provider \u001b[38;5;241m=\u001b[39m _parse_model(model, model_provider)\n\u001b[0;32m--> 474\u001b[0m     creator_func \u001b[38;5;241m=\u001b[39m \u001b[43m_get_chat_model_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m creator_func(model\u001b[38;5;241m=\u001b[39mmodel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/langchain/chat_models/base.py:142\u001b[0m, in \u001b[0;36m_get_chat_model_creator\u001b[0;34m(provider)\u001b[0m\n\u001b[1;32m    140\u001b[0m pkg, class_name, creator_func \u001b[38;5;241m=\u001b[39m _SUPPORTED_PROVIDERS[provider]\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43m_import_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m provider \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/langchain/chat_models/base.py:111\u001b[0m, in \u001b[0;36m_import_module\u001b[0;34m(module, class_name)\u001b[0m\n\u001b[1;32m    106\u001b[0m pkg \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m package. Please install it \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith `pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m )\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Initializing ChatOpenAI requires the langchain-openai package. Please install it with `pip install langchain-openai`"
     ]
    }
   ],
   "source": [
    "## Dataclass\n",
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "@dataclass\n",
    "class ContactInfo:\n",
    "    \"\"\"Contact information for a person.\"\"\"\n",
    "    name: str \n",
    "    email: str \n",
    "    phone: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"groq:qwen/qwen3-32b\",\n",
    "    response_format=ContactInfo  # Auto-selects ProviderStrategy\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> 6989f8d (Added AI scripts)
   "id": "a9062034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
